{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 특정 GPU에 1GB 메모리만 할당하도록 제한\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    except RuntimeError as e:\n",
    "    # 프로그램 시작시에 가상 장치가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyP0AgHnNpIn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D\n",
    "from tensorflow.keras.layers import Dropout, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import gc\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./Data/fashion_mnist/fashion-mnist_train.csv')\n",
    "\n",
    "\n",
    "# Data Split\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df.drop('label', \n",
    "                         axis=1, \n",
    "                         inplace=False), \n",
    "                 df['label'], \n",
    "                 test_size=0.3, \n",
    "                 random_state=0)\n",
    "# test_size : test set의 비율 (0.3 => 30%)\n",
    "# random_state : split할 때 랜덤하게 split하게 되는데 이를 일정하게 고정(seed의 개념)\n",
    "\n",
    "# Min-Max Normalization\n",
    "scaler = MinMaxScaler()   # scaler = StandardScaler()\n",
    "scaler.fit(x_data_train)\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "del x_data_train\n",
    "del x_data_test\n",
    "\n",
    "##### Tensorflow 2.x implementation #####\n",
    "with tf.device('/device:GPU:0'):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Conv2D(필터개수, kernel_size, activation='relu')\n",
    "    model.add(Conv2D(filters=32,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu', \n",
    "                     input_shape=(28,28,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3,3),\n",
    "                     activation='relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=256, \n",
    "                    activation='relu'))\n",
    "    model.add(Dense(units=10, \n",
    "                    activation='softmax'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "    history = model.fit(x_data_train_norm.reshape(-1,28,28,1),\n",
    "                        t_data_train,\n",
    "                        epochs=200,\n",
    "                        batch_size=100,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.3\n",
    "              )\n",
    "\n",
    "    model.evaluate(x_data_test_norm.reshape(-1,28,28,1), t_data_test)\n",
    "\n",
    "    \n",
    "# GPU Memory 해제를 위한 코드이지만 잘 동작하는지는 확인이 필요    \n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN298shM3yG7ilbwJT864cR",
   "collapsed_sections": [],
   "mount_file_id": "1mkZKjcCAgs2RDGLYps9GDDq_z4AYz5Uo",
   "name": "colab_mnist_cnn_tf2.x.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:data_env_TF2] *",
   "language": "python",
   "name": "conda-env-data_env_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
