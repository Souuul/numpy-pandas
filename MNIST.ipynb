{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T1UN5hHJmQLH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbbVX1kuuxt-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('/content/drive/My Drive/MachineLearning/train.csv')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1qssMZs4cvM"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = [0, 1 ,2 ,2 ,2]   # 정답\n",
    "y_pred = [0, 0, 2, 2, 1]   # 우리 model이 예측한 값\n",
    "\n",
    "target_name = ['thin', 'normal', 'fat']\n",
    "\n",
    "print(classification_report(y_true,y_pred,target_names=target_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQoP651CCLSu"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [2, 0, 2, 2, 0 ,1]\n",
    "y_pred = [0, 0, 2, 2, 0, 2]\n",
    "\n",
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3H3-Q2zBagA6"
   },
   "outputs": [],
   "source": [
    "%reset\n",
    "\n",
    "# Tensorflow 1.15버전을 가지고 MNIST예제를 구현\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns    # confusion matrix를 heatmap을 통해서 그래프 출력   \n",
    "from sklearn.preprocessing import MinMaxScaler   # Normalization\n",
    "from sklearn.model_selection import train_test_split # train, test 분리\n",
    "from sklearn.model_selection import KFold        # Cross Validation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 1. Raw Data Loading\n",
    "df = pd.read_csv('/content/drive/My Drive/MachineLearning/train.csv')\n",
    "# display(df.head(), df.shape)   # (42000, 785)\n",
    "\n",
    "# 2. 결측치와 이상치 처리\n",
    "#    결측치를 찾고 만약 결측치가 존재하면 수정\n",
    "#    이상치를 찾고 만약 있으면 이상치를 수정(scipy의 zscore이용하면 편해요!)\n",
    "#    결측치와 이상치가 MNIST는 존재하지 않아요!!\n",
    "\n",
    "# 3. 사용하는 데이터가 이미지 데이터예요!!\n",
    "#    어떤 이미지인지 한번 확인하고 갈께요!!\n",
    "#    df에서 label column은 제외하고 pixel데이터만 들고올꺼예요!!\n",
    "img_data = df.drop('label', axis=1, inplace=False).values  \n",
    "     # 이미지들의 pixel 데이터만 ndarray로 추출(2차원)\n",
    "# 이런 이미지 데이터를 화면에 출력\n",
    "fig = plt.figure()  # 출력할 전체 화면을 지칭하는 객체를 가져와요!\n",
    "# fig안에 subplot을 만들꺼예요!! 이 subplot을 저장할 list를 하나 만들어요!!\n",
    "fig_arr = list()\n",
    "\n",
    "for n in range(10):\n",
    "    fig_arr.append(fig.add_subplot(2,5,n+1))\n",
    "    fig_arr[n].imshow(img_data[n].reshape(28,28), cmap='Greys', \n",
    "                      interpolation='nearest')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Data Split\n",
    "#    데이터는 크게 3부분으로 나누어야 해요!\n",
    "#    일단 2부분으로 나누어요! (train용, test용)\n",
    "#    여기서 train용이라고 되어 있는 데이터를 다시 2부분으로 분리(train,validation)\n",
    "#    train : 학습용(반복학습으로 모델을 완성)\n",
    "#    validation : 모델 수정용도의 데이터 셋\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(df.drop('label', axis=1), df['label'], test_size=0.3, \n",
    "                 random_state=0)\n",
    "                 \n",
    "# 5. Normalization(x_data, 독립변수의 처리)\n",
    "scaler = MinMaxScaler()   # 객체 생성\n",
    "scaler.fit(x_data_train)  # 객체에 정보를 제공\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "del x_data_train   \n",
    "del x_data_test\n",
    "\n",
    "# 6. 지금해결해야 하는 문제가 multinomial이예요!\n",
    "#    t_data(label데이터, 정답)를 one hot 형태로 변형\n",
    "\n",
    "sess = tf.Session()   # Tensorflow node를 실행하기 위해서 session을 생성\n",
    "\n",
    "# depth는 label의 종류 개수\n",
    "t_data_train_onehot = sess.run(tf.one_hot(t_data_train, depth=10))  \n",
    "t_data_test_onehot = sess.run(tf.one_hot(t_data_test, depth=10))\n",
    "\n",
    "###########################################\n",
    "# traing용, test용 데이터가 준비되었어요!!\n",
    "\n",
    "###########################################\n",
    "# Tensorflow 구현\n",
    "\n",
    "# 1. placeholder\n",
    "# X의 의미는 x_data(독립변수)를 받아들이기 위한 placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "\n",
    "# 2. Weight, bias\n",
    "W = tf.Variable(tf.random.normal([784,10]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([10]), name='bias')\n",
    "\n",
    "# 3. Model(Hypothesis)  => Multinomial\n",
    "logit = tf.matmul(X,W) + b   # Linear Regression\n",
    "H = tf.nn.softmax(logit)     # Multinomial Hypothesis\n",
    "\n",
    "# 4. loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,\n",
    "                                                                 labels=T))\n",
    "\n",
    "# 5. Optimizer를 이용한 train(Optimizer는 loss값을 줄이는 알고리즘)\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-1).minimize(loss)\n",
    "\n",
    "# 6. 학습용 parameter setting (기본적으로 2개는 설정)\n",
    "num_of_epoch = 100\n",
    "batch_size = 100\n",
    "\n",
    "# 7. 학습진행\n",
    "def run_train(sess,train_x, train_t):\n",
    "    print('### 학습 시작 ###')\n",
    "    sess.run(tf.global_variables_initializer())  # tf.Variable 초기화(W,b)\n",
    "\n",
    "    total_batch = int(train_x.shape[0] / batch_size)\n",
    "    for step in range(num_of_epoch):\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_t = train_t[i*batch_size:(i+1)*batch_size]\n",
    "            _, loss_val = sess.run([train,loss], feed_dict={X:batch_x,\n",
    "                                                            T:batch_t})\n",
    "        if step % 10 == 0:\n",
    "            print('Loss : {}'.format(loss_val))\n",
    "    print('### 학습 끝 ###')\n",
    "\n",
    "# Accuracy\n",
    "predict = tf.argmax(H,1)   # [[0.1 0.3  0.2 0.2 ... 0.1]]\n",
    "\n",
    "# sklearn을 이용해서 classification_report를 출력해보아요!!\n",
    "target_name = ['num 0', 'num 1', 'num 2', 'num 3',\n",
    "               'num 4', 'num 5', 'num 6', 'num 7',\n",
    "               'num 8', 'num 9']\n",
    "# train데이터로 학습하고 train데이터로 성능평가를 해 보아요!!  \n",
    "\n",
    "run_train(sess,x_data_train_norm,t_data_train_onehot)\n",
    "print(classification_report(t_data_train,\n",
    "                            sess.run(predict, feed_dict={X:x_data_train_norm}),\n",
    "                            target_names=target_name))               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nh0RStKe9vIP"
   },
   "outputs": [],
   "source": [
    "# seaborn을 이용한 confusion matrix의 그래프 출력\n",
    "fig, ax = plt.subplots(figsize=(10,10))  # inch단위로 그림의 크기\n",
    "sns.heatmap(\n",
    "    confusion_matrix(t_data_train,\n",
    "                     sess.run(predict, feed_dict={X:x_data_train_norm})),\n",
    "    annot = True, # 숫자표현\n",
    "    cbar = True,  # color bar \n",
    "    fmt = '3d',    # 정수표현     \n",
    "    cmap = 'Blues', # color 색상\n",
    "    ax = ax       # 그래프로 사용할 subplot\n",
    ")\n",
    "ax.set_xlabel('Predict')\n",
    "ax.set_ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPgYQGqHvZEp"
   },
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow   # 현재 설치된 tensorflow 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pog1F3vx4aT-"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.15 # tensorflow 1.15버전 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xre9F5Ot4Czi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNmHuFqxciuC2LpqyvnN3DS",
   "collapsed_sections": [],
   "mount_file_id": "1qkVmo3woNvn2g21QVrsl-UFefM_0Fdm3",
   "name": "MNIST.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
