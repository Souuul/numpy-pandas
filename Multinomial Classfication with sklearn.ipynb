{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate \n",
    "# 너무 작거나 크면 발산하거나 Local minima가 생김 \n",
    "# 일반적으로 0.001, 0.01 세팅하거나 loss를 봐서 설정해함\n",
    "\n",
    "# Normalization (정규화)\n",
    "# Min-Max Normaliztion\n",
    "# 장점 : 0 ~ 1 사이로 모든 feature를 Scaling\n",
    "# 단점 : 이상치에 취약\n",
    "\n",
    "# Standardization (표준화)\n",
    "# Z-Score Normalization \n",
    "# 장점 : 이상치에 덜 민감함\n",
    "# 단점 : 동일한 척도로 Scaling 을 하지 않음\n",
    "\n",
    "# Student's T분포\n",
    "\n",
    "# underfitting => 너무 대충학습해서 학습이 잘 이루어지지 않은 경우\n",
    "# overfitting => Training Data에 대해 너무 학습이 잘 된 경우 오히려 실제 데이터에 적용이 잘 안되는 케이스\n",
    "\n",
    "# overfitting은 해결해야 하는 문제\n",
    "# 1.  많은 양의 Training data\n",
    "# 가장 기본이 되는 조건인데 우리가 program 적으로 해결이 불가능\n",
    "\n",
    "# 2. Feature의 개수를 줄여야 해요!! \n",
    "# Titanic 예제에서 이름 같은 경우 종속변수와 연관이 없는 독랍변수들 제거 (상관관계 분석)\n",
    "\n",
    "# 3. weight의 값을 인위적으로 조절!\n",
    "# w 의 값이 클수로 curve를 그리게 되고 overfitting 의 여지가 많아져요\n",
    "# Regulazation\n",
    "\n",
    "# 4. Deep learning\n",
    "# Dropout이라는 기능을 사용하여 overfitting 을 피할수 있어요\n",
    "\n",
    "# 5. 학습의 수를 줄여요 ! \n",
    "# 적절한 학습방법의 수를 정해야합니다.\n",
    "# 전체 학습데이터를 이용해서 1번학습 > 1 epoch / epoch수를 적절하게 조절\n",
    "\n",
    "\n",
    "\n",
    "# 평가 (Evaluation)\n",
    "# 우리가 가지고 있는 Training Data Set 을 어떻게 이용해서 성능평가를 할 것인가?\n",
    "# 성능평가 방법은 (Metric)\n",
    "# Precision \n",
    "# Recall \n",
    "# ** Accuracy\n",
    "\n",
    "# 우리가 피해야하는 평가 방법 : Training Data Set 으로 학습한 후 \n",
    "# Training Data Set으로 평가 진행 X 성능이 아주 좋게 나와요\n",
    "# original Data Set\n",
    "# Training Data\n",
    "# Testing Data(최종 평가데이터) : 이 데이터 셋으로 Model을 수정하지 않아요!!\n",
    "\n",
    "# 최종 모델의 Accuracy를 측정하기 위한 Data Set\n",
    "# Training, Validation data set, testing\n",
    "# Validation data set : Model의 개선작업 수행\n",
    "\n",
    "# Evaluation 할때, 데이터가 충분하다면 !! Training, Validation, Testing\n",
    "# 데이터량이 작으면 underfitting epoch의 수를 늘리면 overfitting이 발생\n",
    "# cross validation (cv) - K-fold \n",
    "# K :상수값 만약 K=5 이면 fold를 5개로 나눔 5개로 나누고 테스트와 Training을 반복\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Classfication \n",
    "# BMI 지수에 대한 데이터를 가지고 학습 후 예측까지 진행해 볼꺼에요!!\n",
    "# BMI 지수는 키와 몸무게를 가지고 저체중, 정상, 과체중, 비만을 판단하는 지수\n",
    "# BMI = 자신의 몸무게(kg) / 키의 제곱(m)\n",
    "# 18.5 이하면 저체중\n",
    "# 18.5 ~23 정상\n",
    "# 23 ~ 25 과체중\n",
    "# 25이상 비만\n",
    "\n",
    "# 우리가 하려는건 식이 아니라 BMI지수를 조사한 데이터가 있어요\n",
    "# 이걸 학습해서 예측을 통해 나의 BMI지수를 알아보려고 합니다.\n",
    "# 단, 제공하는 데이터는 4가지 분류가 아니라 3가지 분류로 나누어져 있어요!\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/bmi.csv', skiprows=3)\n",
    "\n",
    "# 결측치부터 확인!\n",
    "# df.isnull().sum()\n",
    "\n",
    "# 이상치확인\n",
    "# Z-score\n",
    "\n",
    "zscore_threshold = 1.8\n",
    "\n",
    "for col in df.columns:\n",
    "    outlier = df[col][np.abs(stats.zscore(df[col])) > zscore_threshold]    \n",
    "    df = df.loc[~df[col].isin(outlier)]\n",
    "    \n",
    "    \n",
    "df.loc[np.abs(stats.zscore(df['height']))>=zscore_threshold,:] # height\n",
    "df.loc[np.abs(stats.zscore(df['weight']))>=zscore_threshold,:] # weight\n",
    "df.loc[np.abs(stats.zscore(df['label']))>=zscore_threshold,:] # label\n",
    "\n",
    "# Data Split\n",
    "# Train, Test 두 부분으로 분할\n",
    "# 분리하는 비율은 7:3 으로 분리.\n",
    "# 나중에 Train 부분은 K-fold cross validation을 진행할 꺼에요!\n",
    "\n",
    "# 역슬레시로 칸넘기기\n",
    "x_data_train, x_data_test, t_data_train, t_data_test =\\\n",
    "train_test_split(df[['height', 'weight']], df['label'], test_size=0.3, random_state=0) # 30% 테스트 사이즈\n",
    "\n",
    "display(x_data_train)\n",
    "display(x_data_test)\n",
    "\n",
    "#Normalization\n",
    "scaler = MinMaxScaler() # scaler 객체를 생성해요!\n",
    "scaler.fit(x_data_train) # scaler 객체에 최대, 최소와 같은 정보가 들어가요!\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "del x_data_train #혼동을 방지하기 위해서 변수를 삭제\n",
    "del x_data_test\n",
    "\n",
    "# sklearn 구현은 매우매우 간단 !!\n",
    "model = LogisticRegression()\n",
    "model.fit(x_data_train_norm, t_data_train)\n",
    "\n",
    "# 우리 model의 정확도를 측정해야 해요!\n",
    "# cross validation\n",
    "kfold = 10 \n",
    "kfold_score = cross_val_score(model, x_data_train_norm, t_data_train, cv = kfold)\n",
    "print('##########cross validation############')\n",
    "\n",
    "print('score : {}'.format(kfold_score))\n",
    "print('전체평균은 : {}'.format(kfold_score.mean()))\n",
    "\n",
    "# 최종모델평가\n",
    "predict_val = model.predict(x_data_test_norm) #테스트데이터로 예측값을 구해요!\n",
    "acc = accuracy_score(predict_val, t_data_test)\n",
    "print('우리 model의 최종 Accuracy : {}'.format(acc))\n",
    "\n",
    "# Predict\n",
    "height = 188\n",
    "weight = 78\n",
    "my_state = [[height, weight]]\n",
    "my_state_val = model.predict(scaler.transform(my_state))\n",
    "\n",
    "print(my_state_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
