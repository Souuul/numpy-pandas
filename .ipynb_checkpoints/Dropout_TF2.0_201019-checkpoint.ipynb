{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label       0\n",
      "pixel0      0\n",
      "pixel1      0\n",
      "pixel2      0\n",
      "pixel3      0\n",
      "           ..\n",
      "pixel779    0\n",
      "pixel780    0\n",
      "pixel781    0\n",
      "pixel782    0\n",
      "pixel783    0\n",
      "Length: 785, dtype: int64\n",
      "Train on 20580 samples, validate on 8820 samples\n",
      "Epoch 1/100\n",
      "20580/20580 [==============================] - 3s 138us/sample - loss: 0.5012 - categorical_accuracy: 0.8438 - val_loss: 0.2289 - val_categorical_accuracy: 0.9304\n",
      "Epoch 2/100\n",
      "20580/20580 [==============================] - 2s 95us/sample - loss: 0.2085 - categorical_accuracy: 0.9355 - val_loss: 0.1534 - val_categorical_accuracy: 0.9563\n",
      "Epoch 3/100\n",
      "20580/20580 [==============================] - 2s 95us/sample - loss: 0.1450 - categorical_accuracy: 0.9543 - val_loss: 0.1298 - val_categorical_accuracy: 0.9616\n",
      "Epoch 4/100\n",
      "20580/20580 [==============================] - 2s 99us/sample - loss: 0.1136 - categorical_accuracy: 0.9640 - val_loss: 0.1329 - val_categorical_accuracy: 0.9611\n",
      "Epoch 5/100\n",
      "20580/20580 [==============================] - 2s 94us/sample - loss: 0.0886 - categorical_accuracy: 0.9718 - val_loss: 0.1167 - val_categorical_accuracy: 0.9677\n",
      "Epoch 6/100\n",
      "20580/20580 [==============================] - 2s 95us/sample - loss: 0.0703 - categorical_accuracy: 0.9787 - val_loss: 0.1117 - val_categorical_accuracy: 0.9695\n",
      "Epoch 7/100\n",
      "20580/20580 [==============================] - 2s 102us/sample - loss: 0.0613 - categorical_accuracy: 0.9799 - val_loss: 0.1109 - val_categorical_accuracy: 0.9684\n",
      "Epoch 8/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0536 - categorical_accuracy: 0.9818 - val_loss: 0.1220 - val_categorical_accuracy: 0.9683\n",
      "Epoch 9/100\n",
      "20580/20580 [==============================] - 2s 102us/sample - loss: 0.0481 - categorical_accuracy: 0.9840 - val_loss: 0.1031 - val_categorical_accuracy: 0.9723\n",
      "Epoch 10/100\n",
      "20580/20580 [==============================] - 2s 102us/sample - loss: 0.0407 - categorical_accuracy: 0.9855 - val_loss: 0.1037 - val_categorical_accuracy: 0.9724\n",
      "Epoch 11/100\n",
      "20580/20580 [==============================] - 2s 102us/sample - loss: 0.0331 - categorical_accuracy: 0.9896 - val_loss: 0.1103 - val_categorical_accuracy: 0.9729\n",
      "Epoch 12/100\n",
      "20580/20580 [==============================] - 2s 101us/sample - loss: 0.0341 - categorical_accuracy: 0.9891 - val_loss: 0.1096 - val_categorical_accuracy: 0.9728\n",
      "Epoch 13/100\n",
      "20580/20580 [==============================] - 2s 101us/sample - loss: 0.0282 - categorical_accuracy: 0.9902 - val_loss: 0.1121 - val_categorical_accuracy: 0.9726\n",
      "Epoch 14/100\n",
      "20580/20580 [==============================] - 2s 101us/sample - loss: 0.0279 - categorical_accuracy: 0.9912 - val_loss: 0.1156 - val_categorical_accuracy: 0.9738\n",
      "Epoch 15/100\n",
      "20580/20580 [==============================] - 2s 100us/sample - loss: 0.0233 - categorical_accuracy: 0.9928 - val_loss: 0.1151 - val_categorical_accuracy: 0.9721\n",
      "Epoch 16/100\n",
      "20580/20580 [==============================] - 2s 100us/sample - loss: 0.0264 - categorical_accuracy: 0.9907 - val_loss: 0.1143 - val_categorical_accuracy: 0.9743\n",
      "Epoch 17/100\n",
      "20580/20580 [==============================] - 2s 101us/sample - loss: 0.0231 - categorical_accuracy: 0.9919 - val_loss: 0.1177 - val_categorical_accuracy: 0.9732\n",
      "Epoch 18/100\n",
      "20580/20580 [==============================] - 2s 100us/sample - loss: 0.0251 - categorical_accuracy: 0.9911 - val_loss: 0.1185 - val_categorical_accuracy: 0.9738\n",
      "Epoch 19/100\n",
      "20580/20580 [==============================] - 2s 101us/sample - loss: 0.0213 - categorical_accuracy: 0.9925 - val_loss: 0.1375 - val_categorical_accuracy: 0.9710\n",
      "Epoch 20/100\n",
      "20580/20580 [==============================] - 2s 102us/sample - loss: 0.0176 - categorical_accuracy: 0.9936 - val_loss: 0.1300 - val_categorical_accuracy: 0.9720\n",
      "Epoch 21/100\n",
      "20580/20580 [==============================] - 2s 101us/sample - loss: 0.0188 - categorical_accuracy: 0.9932 - val_loss: 0.1258 - val_categorical_accuracy: 0.9714\n",
      "Epoch 22/100\n",
      "20580/20580 [==============================] - 2s 101us/sample - loss: 0.0168 - categorical_accuracy: 0.9945 - val_loss: 0.1330 - val_categorical_accuracy: 0.9728\n",
      "Epoch 23/100\n",
      "20580/20580 [==============================] - 2s 102us/sample - loss: 0.0144 - categorical_accuracy: 0.9955 - val_loss: 0.1529 - val_categorical_accuracy: 0.9689\n",
      "Epoch 24/100\n",
      "20580/20580 [==============================] - 2s 109us/sample - loss: 0.0147 - categorical_accuracy: 0.9950 - val_loss: 0.1332 - val_categorical_accuracy: 0.9721\n",
      "Epoch 25/100\n",
      "20580/20580 [==============================] - 2s 104us/sample - loss: 0.0139 - categorical_accuracy: 0.9956 - val_loss: 0.1375 - val_categorical_accuracy: 0.9731\n",
      "Epoch 26/100\n",
      "20580/20580 [==============================] - 2s 103us/sample - loss: 0.0144 - categorical_accuracy: 0.9949 - val_loss: 0.1480 - val_categorical_accuracy: 0.9728\n",
      "Epoch 27/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0156 - categorical_accuracy: 0.9946 - val_loss: 0.1327 - val_categorical_accuracy: 0.9738\n",
      "Epoch 28/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0185 - categorical_accuracy: 0.9944 - val_loss: 0.1358 - val_categorical_accuracy: 0.9731\n",
      "Epoch 29/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0174 - categorical_accuracy: 0.9943 - val_loss: 0.1618 - val_categorical_accuracy: 0.9711\n",
      "Epoch 30/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0154 - categorical_accuracy: 0.9947 - val_loss: 0.1289 - val_categorical_accuracy: 0.9752\n",
      "Epoch 31/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0132 - categorical_accuracy: 0.9958 - val_loss: 0.1519 - val_categorical_accuracy: 0.9729\n",
      "Epoch 32/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0147 - categorical_accuracy: 0.9948 - val_loss: 0.1458 - val_categorical_accuracy: 0.9740\n",
      "Epoch 33/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0168 - categorical_accuracy: 0.9945 - val_loss: 0.1490 - val_categorical_accuracy: 0.9731\n",
      "Epoch 34/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0185 - categorical_accuracy: 0.9942 - val_loss: 0.1384 - val_categorical_accuracy: 0.9730\n",
      "Epoch 35/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0118 - categorical_accuracy: 0.9962 - val_loss: 0.1426 - val_categorical_accuracy: 0.9730\n",
      "Epoch 36/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0161 - categorical_accuracy: 0.9945 - val_loss: 0.1558 - val_categorical_accuracy: 0.9734\n",
      "Epoch 37/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0140 - categorical_accuracy: 0.9956 - val_loss: 0.1599 - val_categorical_accuracy: 0.9729\n",
      "Epoch 38/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0085 - categorical_accuracy: 0.9972 - val_loss: 0.1588 - val_categorical_accuracy: 0.9721\n",
      "Epoch 39/100\n",
      "20580/20580 [==============================] - 2s 112us/sample - loss: 0.0116 - categorical_accuracy: 0.9961 - val_loss: 0.1515 - val_categorical_accuracy: 0.9726\n",
      "Epoch 40/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0124 - categorical_accuracy: 0.9958 - val_loss: 0.1631 - val_categorical_accuracy: 0.9732\n",
      "Epoch 41/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0161 - categorical_accuracy: 0.9946 - val_loss: 0.1539 - val_categorical_accuracy: 0.9728\n",
      "Epoch 42/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0130 - categorical_accuracy: 0.9961 - val_loss: 0.1378 - val_categorical_accuracy: 0.9753\n",
      "Epoch 43/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0106 - categorical_accuracy: 0.9967 - val_loss: 0.1540 - val_categorical_accuracy: 0.9756\n",
      "Epoch 44/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0137 - categorical_accuracy: 0.9951 - val_loss: 0.1570 - val_categorical_accuracy: 0.9736\n",
      "Epoch 45/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0122 - categorical_accuracy: 0.9958 - val_loss: 0.1566 - val_categorical_accuracy: 0.9744\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0089 - categorical_accuracy: 0.9965 - val_loss: 0.1737 - val_categorical_accuracy: 0.9749\n",
      "Epoch 47/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0105 - categorical_accuracy: 0.9965 - val_loss: 0.1570 - val_categorical_accuracy: 0.9749\n",
      "Epoch 48/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0120 - categorical_accuracy: 0.9960 - val_loss: 0.1558 - val_categorical_accuracy: 0.9766\n",
      "Epoch 49/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0141 - categorical_accuracy: 0.9952 - val_loss: 0.1683 - val_categorical_accuracy: 0.9749\n",
      "Epoch 50/100\n",
      "20580/20580 [==============================] - 2s 108us/sample - loss: 0.0127 - categorical_accuracy: 0.9952 - val_loss: 0.1697 - val_categorical_accuracy: 0.9735\n",
      "Epoch 51/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0138 - categorical_accuracy: 0.9956 - val_loss: 0.1652 - val_categorical_accuracy: 0.9736\n",
      "Epoch 52/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0114 - categorical_accuracy: 0.9967 - val_loss: 0.1660 - val_categorical_accuracy: 0.9736\n",
      "Epoch 53/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0111 - categorical_accuracy: 0.9962 - val_loss: 0.1565 - val_categorical_accuracy: 0.9739\n",
      "Epoch 54/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0112 - categorical_accuracy: 0.9963 - val_loss: 0.1754 - val_categorical_accuracy: 0.9736\n",
      "Epoch 55/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0155 - categorical_accuracy: 0.9952 - val_loss: 0.1576 - val_categorical_accuracy: 0.9751\n",
      "Epoch 56/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0115 - categorical_accuracy: 0.9963 - val_loss: 0.1613 - val_categorical_accuracy: 0.9748\n",
      "Epoch 57/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0109 - categorical_accuracy: 0.9967 - val_loss: 0.1696 - val_categorical_accuracy: 0.9734\n",
      "Epoch 58/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0095 - categorical_accuracy: 0.9968 - val_loss: 0.1605 - val_categorical_accuracy: 0.9757\n",
      "Epoch 59/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0109 - categorical_accuracy: 0.9965 - val_loss: 0.1592 - val_categorical_accuracy: 0.9751\n",
      "Epoch 60/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0136 - categorical_accuracy: 0.9961 - val_loss: 0.1418 - val_categorical_accuracy: 0.9768\n",
      "Epoch 61/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0066 - categorical_accuracy: 0.9976 - val_loss: 0.1488 - val_categorical_accuracy: 0.9765\n",
      "Epoch 62/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0076 - categorical_accuracy: 0.9976 - val_loss: 0.1604 - val_categorical_accuracy: 0.9740\n",
      "Epoch 63/100\n",
      "20580/20580 [==============================] - 2s 107us/sample - loss: 0.0103 - categorical_accuracy: 0.9967 - val_loss: 0.1432 - val_categorical_accuracy: 0.9781\n",
      "Epoch 64/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0096 - categorical_accuracy: 0.9969 - val_loss: 0.1755 - val_categorical_accuracy: 0.9738\n",
      "Epoch 65/100\n",
      "20580/20580 [==============================] - 2s 109us/sample - loss: 0.0102 - categorical_accuracy: 0.9962 - val_loss: 0.1704 - val_categorical_accuracy: 0.9768\n",
      "Epoch 66/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0096 - categorical_accuracy: 0.9968 - val_loss: 0.1661 - val_categorical_accuracy: 0.9740\n",
      "Epoch 67/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0071 - categorical_accuracy: 0.9979 - val_loss: 0.1528 - val_categorical_accuracy: 0.9759\n",
      "Epoch 68/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0064 - categorical_accuracy: 0.9981 - val_loss: 0.1670 - val_categorical_accuracy: 0.9752\n",
      "Epoch 69/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0090 - categorical_accuracy: 0.9971 - val_loss: 0.1578 - val_categorical_accuracy: 0.9738\n",
      "Epoch 70/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0071 - categorical_accuracy: 0.9973 - val_loss: 0.1651 - val_categorical_accuracy: 0.9764\n",
      "Epoch 71/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0079 - categorical_accuracy: 0.9978 - val_loss: 0.1894 - val_categorical_accuracy: 0.9738\n",
      "Epoch 72/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0108 - categorical_accuracy: 0.9968 - val_loss: 0.1633 - val_categorical_accuracy: 0.9766\n",
      "Epoch 73/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0101 - categorical_accuracy: 0.9962 - val_loss: 0.1722 - val_categorical_accuracy: 0.9747\n",
      "Epoch 74/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0088 - categorical_accuracy: 0.9972 - val_loss: 0.1724 - val_categorical_accuracy: 0.9756\n",
      "Epoch 75/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0070 - categorical_accuracy: 0.9976 - val_loss: 0.1580 - val_categorical_accuracy: 0.9769\n",
      "Epoch 76/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0093 - categorical_accuracy: 0.9971 - val_loss: 0.1816 - val_categorical_accuracy: 0.9741\n",
      "Epoch 77/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0070 - categorical_accuracy: 0.9977 - val_loss: 0.1786 - val_categorical_accuracy: 0.9736\n",
      "Epoch 78/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0113 - categorical_accuracy: 0.9966 - val_loss: 0.1808 - val_categorical_accuracy: 0.9749\n",
      "Epoch 79/100\n",
      "20580/20580 [==============================] - 2s 108us/sample - loss: 0.0159 - categorical_accuracy: 0.9953 - val_loss: 0.1618 - val_categorical_accuracy: 0.9765\n",
      "Epoch 80/100\n",
      "20580/20580 [==============================] - 2s 113us/sample - loss: 0.0131 - categorical_accuracy: 0.9964 - val_loss: 0.1674 - val_categorical_accuracy: 0.9740\n",
      "Epoch 81/100\n",
      "20580/20580 [==============================] - 2s 107us/sample - loss: 0.0117 - categorical_accuracy: 0.9961 - val_loss: 0.1859 - val_categorical_accuracy: 0.9726\n",
      "Epoch 82/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0071 - categorical_accuracy: 0.9981 - val_loss: 0.1772 - val_categorical_accuracy: 0.9745\n",
      "Epoch 83/100\n",
      "20580/20580 [==============================] - 2s 108us/sample - loss: 0.0088 - categorical_accuracy: 0.9974 - val_loss: 0.1703 - val_categorical_accuracy: 0.9753\n",
      "Epoch 84/100\n",
      "20580/20580 [==============================] - 2s 107us/sample - loss: 0.0071 - categorical_accuracy: 0.9976 - val_loss: 0.1792 - val_categorical_accuracy: 0.9761\n",
      "Epoch 85/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0067 - categorical_accuracy: 0.9978 - val_loss: 0.2006 - val_categorical_accuracy: 0.9744\n",
      "Epoch 86/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0106 - categorical_accuracy: 0.9970 - val_loss: 0.1913 - val_categorical_accuracy: 0.9744\n",
      "Epoch 87/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0078 - categorical_accuracy: 0.9974 - val_loss: 0.1786 - val_categorical_accuracy: 0.9761\n",
      "Epoch 88/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0079 - categorical_accuracy: 0.9981 - val_loss: 0.1822 - val_categorical_accuracy: 0.9752\n",
      "Epoch 89/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0071 - categorical_accuracy: 0.9972 - val_loss: 0.1808 - val_categorical_accuracy: 0.9774\n",
      "Epoch 90/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0050 - categorical_accuracy: 0.9984 - val_loss: 0.1910 - val_categorical_accuracy: 0.9763\n",
      "Epoch 91/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0107 - categorical_accuracy: 0.9968 - val_loss: 0.2004 - val_categorical_accuracy: 0.9744\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0101 - categorical_accuracy: 0.9968 - val_loss: 0.1965 - val_categorical_accuracy: 0.9741\n",
      "Epoch 93/100\n",
      "20580/20580 [==============================] - 2s 106us/sample - loss: 0.0114 - categorical_accuracy: 0.9968 - val_loss: 0.1839 - val_categorical_accuracy: 0.9748\n",
      "Epoch 94/100\n",
      "20580/20580 [==============================] - 2s 110us/sample - loss: 0.0065 - categorical_accuracy: 0.9982 - val_loss: 0.1863 - val_categorical_accuracy: 0.9761\n",
      "Epoch 95/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0079 - categorical_accuracy: 0.9974 - val_loss: 0.1758 - val_categorical_accuracy: 0.9752\n",
      "Epoch 96/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0066 - categorical_accuracy: 0.9977 - val_loss: 0.1794 - val_categorical_accuracy: 0.9765\n",
      "Epoch 97/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0041 - categorical_accuracy: 0.9984 - val_loss: 0.1805 - val_categorical_accuracy: 0.9757\n",
      "Epoch 98/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0059 - categorical_accuracy: 0.9981 - val_loss: 0.1916 - val_categorical_accuracy: 0.9751\n",
      "Epoch 99/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0080 - categorical_accuracy: 0.9974 - val_loss: 0.1925 - val_categorical_accuracy: 0.9757\n",
      "Epoch 100/100\n",
      "20580/20580 [==============================] - 2s 105us/sample - loss: 0.0106 - categorical_accuracy: 0.9969 - val_loss: 0.1905 - val_categorical_accuracy: 0.9760\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder # Normalization\n",
    "from sklearn.model_selection import train_test_split # train, test 데이터분리\n",
    "from sklearn.model_selection import KFold # cross validation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from scipy import stats\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/admin/Downloads/Digit_Recognizer_train.csv')\n",
    "display(df)\n",
    "# 결측치확인\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "# Data split\n",
    "x_data_train, x_data_test, t_data_train, t_data_test =\\\n",
    "train_test_split(df.iloc[:,1:], df.iloc[:,0], test_size = 0.3, random_state=0)\n",
    "\n",
    "# Normalization\n",
    "x_data_scaler = MinMaxScaler()\n",
    "x_data_scaler.fit(x_data_train)\n",
    "x_data_train_norm = x_data_scaler.transform(x_data_train)\n",
    "x_data_test_norm = x_data_scaler.transform(x_data_test)\n",
    "t_data_train_onehot = to_categorical(t_data_train)\n",
    "t_data_test_onehot = to_categorical(t_data_test)\n",
    "\n",
    "# t_data_train_onehot = OneHotEncoder(sparse=False).fit(pd.DataFrame(t_data_train.reshape(-1, 1)))\n",
    "# t_data_test_onehot = OneHotEncoder(sparse=False).fit(pd.DataFrame(t_data_test.reshape(-1, 1)))\n",
    "\n",
    "\n",
    "# TF 2.0 구현 \n",
    "keras_model = Sequential()\n",
    "keras_model.add(Flatten(input_shape=(784,))) # 아래행처럼 더하기가 가능\n",
    "keras_model.add(Dense(420, activation='relu', kernel_initializer='he_uniform'))\n",
    "keras_model.add(Dropout(0.3))\n",
    "keras_model.add(Dense(258, activation='relu', kernel_initializer='he_uniform'))\n",
    "keras_model.add(Dropout(0.3))\n",
    "keras_model.add(Dense(10, activation='softmax', kernel_initializer='he_uniform'))\n",
    "\n",
    "\n",
    "keras_model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy',\n",
    "                    metrics=['categorical_accuracy']) # sparse 으로 판단도 가능합니다.\n",
    "\n",
    "\n",
    "history = keras_model.fit(x_data_train_norm, t_data_train_onehot, \n",
    "                         epochs = 100, verbose = 1, batch_size=128, validation_split=0.3)\n",
    "\n",
    "predict_val = np.argmax(keras_model.predict(x_data_test_norm), axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1242\n",
      "           1       0.99      0.99      0.99      1429\n",
      "           2       0.97      0.98      0.98      1276\n",
      "           3       0.98      0.97      0.97      1298\n",
      "           4       0.98      0.98      0.98      1236\n",
      "           5       0.98      0.97      0.98      1119\n",
      "           6       0.98      0.99      0.99      1243\n",
      "           7       0.98      0.97      0.98      1334\n",
      "           8       0.95      0.97      0.96      1204\n",
      "           9       0.97      0.96      0.96      1219\n",
      "\n",
      "    accuracy                           0.98     12600\n",
      "   macro avg       0.98      0.98      0.98     12600\n",
      "weighted avg       0.98      0.98      0.98     12600\n",
      "\n",
      "<class 'tensorflow.python.keras.callbacks.History'>\n",
      "dict_keys(['loss', 'categorical_accuracy', 'val_loss', 'val_categorical_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(classification_report(t_data_test, predict_val.ravel()))\n",
    "\n",
    "print(type(history))\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['val_categorical_accuracy'], color='b')\n",
    "plt.plot(history.history['categorical_accuracy'], color='r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_tensorflow2] *",
   "language": "python",
   "name": "conda-env-data_env_tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
