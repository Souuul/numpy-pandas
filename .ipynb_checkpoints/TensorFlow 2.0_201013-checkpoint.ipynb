{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# 버전확인부터 해 보아요!\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05326872 0.02018983]\n",
      " [0.47199104 0.86862337]]\n",
      "tf.Tensor([-0.46128452], shape=(1,), dtype=float32)\n",
      "[-0.46128452]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "random1 = np.random.rand(2,2)\n",
    "print(random1)\n",
    "\n",
    "# Tensorflow\n",
    "\n",
    "random2 = tf.random.normal([1], dtype = tf.float32)\n",
    "print(random2) # Tensor가 출력되요!\n",
    "# TF 1.x버전에서는 node가 가지는 값을 얻어올려면\n",
    "# (Node를 실행 시키려면 Session이 있어야 했어요!!)\n",
    "\n",
    "# TF 2.x버전에서는 session 없이 즉시 실행시킬수 있어요 (Eager Execution)\n",
    "print(random2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c의 값은 : 30.0\n",
      "60.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(10, dtype=tf.float32)\n",
    "b = tf.constant(20, dtype=tf.float32)\n",
    "\n",
    "c = a + b\n",
    "\n",
    "print ('c의 값은 : {}'.format(c.numpy())) \n",
    "\n",
    "d = 30.0\n",
    "# numpy를 tensor로 tensor를 numpy로 변경가능\n",
    "tensor_d = tf.convert_to_tensor(d)\n",
    "print((c+ tensor_d).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.47497696]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "W = tf.Variable(tf.random.normal([1]), name='weight')\n",
    "\n",
    "# 기존에는 tf.Variable()을 이용해서 변수를 만들면 사용하기 전에\n",
    "# 반드시 초기화를 진행해야 했어요!\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# Tf 2.0에서는 초기화를 안해도 되요!!\n",
    "print(W.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow graph에 입력을 주는 부분이 없어졌어요!\n",
    "# 기존에는 graph에게 데이터를 밀어넣기 위해서 placeholder를 이용했어요!\n",
    "# Eager Execution에 의해서 이제는 placeholder가 필요 없게 됬어요!\n",
    "# placeholder는 삭제되었습니다. \n",
    "\n",
    "# Lazy execution을 하지 않아요! 이젠 Eager Execution을 수행해요!\n",
    "# TF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_50_input to have shape (2,) but got array with shape (784,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-46b66046b7bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# model 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/data_env_tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_env_tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_env_tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         steps=steps_per_epoch)\n\u001b[0m\u001b[1;32m    517\u001b[0m     (x, y, sample_weights,\n\u001b[1;32m    518\u001b[0m      \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_env_tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data_env_tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected flatten_50_input to have shape (2,) but got array with shape (784,)"
     ]
    }
   ],
   "source": [
    "# tensorflow의 keras를 이용하여 Model을 생성해 보아요!\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "# model = Sequential # keras model 생성 큰 박스 생성\n",
    "model = tf.keras.models.Sequential()  # keras model 생성 큰 박스 생성\n",
    "# model을 만들었으니 그 다음에는 layer를 만들어야해요!\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(2, ))) # 독립변수의 개수\n",
    "model.add(tf.keras.layers.Dense(3, activation = 'softmax')) # output이 몇개인지 logistic이 몇개인지\n",
    "\n",
    "# model compile 과정\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "def my_loss():\n",
    "    pass\n",
    "          \n",
    "    \n",
    "# model 학습\n",
    "model.fit(x_data_train, t_data_train, epochs=100, batch_size=100, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리 KNN의 사용법에 대해서 알아보아요!!\n",
    "# sklearn을 이용해서 알아보아요!!\n",
    "\n",
    "# BMI 예제를 이용해서 학습한 후 정확도를 측정해 보아요!\n",
    "# \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/bmi.csv', skiprows=3)\n",
    "\n",
    "# data split\n",
    "x_data_train, x_data_test, t_data_train, t_data_test =\\\n",
    "train_test_split(df[['height', 'weight']],df['label'],test_size=0.3, random_state=0)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data_train)\n",
    "x_data_train_norm = scaler.transform(x_data_train)\n",
    "x_data_test_norm = scaler.transform(x_data_test)\n",
    "\n",
    "# Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_data_train_norm, t_data_train) # 학습\n",
    "print(model.score(x_data_test_norm, t_data_test)) # 정확도 확인\n",
    "\n",
    "\n",
    "# KNN을 이용한 분류\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3) # 이웃 3개 찾으라는 얘기\n",
    "knn_model.fit(x_data_train_norm, t_data_train)\n",
    "print(knn_model.score(x_data_test_norm, t_data_test)) # 정확도 확인\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>74</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.3</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>30.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>70</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>77</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>14.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>75</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>18.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>20.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ozone  Solar.R  Wind  Temp  Month  Day\n",
       "0     41.0    190.0   7.4    67      5    1\n",
       "1     36.0    118.0   8.0    72      5    2\n",
       "2     12.0    149.0  12.6    74      5    3\n",
       "3     18.0    313.0  11.5    62      5    4\n",
       "4      NaN      NaN  14.3    56      5    5\n",
       "..     ...      ...   ...   ...    ...  ...\n",
       "148   30.0    193.0   6.9    70      9   26\n",
       "149    NaN    145.0  13.2    77      9   27\n",
       "150   14.0    191.0  14.3    75      9   28\n",
       "151   18.0    131.0   8.0    76      9   29\n",
       "152   20.0    223.0  11.5    68      9   30\n",
       "\n",
       "[153 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>205.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>30.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>14.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>18.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>20.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ozone  Solar.R  Wind  Temp\n",
       "0     41.0    190.0   7.4    67\n",
       "1     36.0    118.0   8.0    72\n",
       "2     12.0    149.0  12.6    74\n",
       "3     18.0    313.0  11.5    62\n",
       "4      NaN    205.0  14.3    56\n",
       "..     ...      ...   ...   ...\n",
       "148   30.0    193.0   6.9    70\n",
       "149    NaN    145.0  13.2    77\n",
       "150   14.0    191.0  14.3    75\n",
       "151   18.0    131.0   8.0    76\n",
       "152   20.0    223.0  11.5    68\n",
       "\n",
       "[153 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Solar.R</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>56</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>69</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>57</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>58</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>57</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>63</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>30.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>70</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>14.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>75</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>18.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>76</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>20.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>68</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ozone  Solar.R  Temp  Wind\n",
       "4     50.0    205.0    56  14.3\n",
       "9     50.0    194.0    69   8.6\n",
       "24    50.0     66.0    57  16.6\n",
       "25    30.0    266.0    58  14.9\n",
       "26    50.0    205.0    57   8.0\n",
       "..     ...      ...   ...   ...\n",
       "147   14.0     20.0    63  16.6\n",
       "148   30.0    193.0    70   6.9\n",
       "150   14.0    191.0    75  14.3\n",
       "151   18.0    131.0    76   8.0\n",
       "152   20.0    223.0    68  11.5\n",
       "\n",
       "[153 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.34104077]\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 153 samples\n",
      "Epoch 1/500\n",
      "153/153 [==============================] - 0s 1ms/sample - loss: 4525681804919802096965910528.0000\n",
      "Epoch 2/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: inf                              \n",
      "Epoch 3/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 4/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 5/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 6/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 7/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 8/500\n",
      "153/153 [==============================] - 0s 61us/sample - loss: nan\n",
      "Epoch 9/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 10/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 11/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 12/500\n",
      "153/153 [==============================] - 0s 51us/sample - loss: nan\n",
      "Epoch 13/500\n",
      "153/153 [==============================] - 0s 57us/sample - loss: nan\n",
      "Epoch 14/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 15/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 16/500\n",
      "153/153 [==============================] - 0s 57us/sample - loss: nan\n",
      "Epoch 17/500\n",
      "153/153 [==============================] - 0s 69us/sample - loss: nan\n",
      "Epoch 18/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 19/500\n",
      "153/153 [==============================] - 0s 52us/sample - loss: nan\n",
      "Epoch 20/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 21/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 22/500\n",
      "153/153 [==============================] - 0s 64us/sample - loss: nan\n",
      "Epoch 23/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 24/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 25/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 26/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 27/500\n",
      "153/153 [==============================] - 0s 72us/sample - loss: nan\n",
      "Epoch 28/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 29/500\n",
      "153/153 [==============================] - 0s 57us/sample - loss: nan\n",
      "Epoch 30/500\n",
      "153/153 [==============================] - 0s 58us/sample - loss: nan\n",
      "Epoch 31/500\n",
      "153/153 [==============================] - 0s 59us/sample - loss: nan\n",
      "Epoch 32/500\n",
      "153/153 [==============================] - 0s 52us/sample - loss: nan\n",
      "Epoch 33/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 34/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 35/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 36/500\n",
      "153/153 [==============================] - 0s 58us/sample - loss: nan\n",
      "Epoch 37/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 38/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 39/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 40/500\n",
      "153/153 [==============================] - 0s 64us/sample - loss: nan\n",
      "Epoch 41/500\n",
      "153/153 [==============================] - 0s 66us/sample - loss: nan\n",
      "Epoch 42/500\n",
      "153/153 [==============================] - 0s 55us/sample - loss: nan\n",
      "Epoch 43/500\n",
      "153/153 [==============================] - 0s 51us/sample - loss: nan\n",
      "Epoch 44/500\n",
      "153/153 [==============================] - 0s 58us/sample - loss: nan\n",
      "Epoch 45/500\n",
      "153/153 [==============================] - 0s 63us/sample - loss: nan\n",
      "Epoch 46/500\n",
      "153/153 [==============================] - 0s 53us/sample - loss: nan\n",
      "Epoch 47/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 48/500\n",
      "153/153 [==============================] - 0s 52us/sample - loss: nan\n",
      "Epoch 49/500\n",
      "153/153 [==============================] - 0s 74us/sample - loss: nan\n",
      "Epoch 50/500\n",
      "153/153 [==============================] - 0s 81us/sample - loss: nan\n",
      "Epoch 51/500\n",
      "153/153 [==============================] - 0s 54us/sample - loss: nan\n",
      "Epoch 52/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 53/500\n",
      "153/153 [==============================] - 0s 55us/sample - loss: nan\n",
      "Epoch 54/500\n",
      "153/153 [==============================] - 0s 63us/sample - loss: nan\n",
      "Epoch 55/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 56/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 57/500\n",
      "153/153 [==============================] - 0s 52us/sample - loss: nan\n",
      "Epoch 58/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 59/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 60/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 61/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 62/500\n",
      "153/153 [==============================] - 0s 52us/sample - loss: nan\n",
      "Epoch 63/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 64/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 65/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 66/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 67/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 68/500\n",
      "153/153 [==============================] - 0s 58us/sample - loss: nan\n",
      "Epoch 69/500\n",
      "153/153 [==============================] - 0s 53us/sample - loss: nan\n",
      "Epoch 70/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 71/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 72/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 73/500\n",
      "153/153 [==============================] - 0s 51us/sample - loss: nan\n",
      "Epoch 74/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 75/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 76/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 77/500\n",
      "153/153 [==============================] - 0s 56us/sample - loss: nan\n",
      "Epoch 78/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 79/500\n",
      "153/153 [==============================] - 0s 59us/sample - loss: nan\n",
      "Epoch 80/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 81/500\n",
      "153/153 [==============================] - 0s 54us/sample - loss: nan\n",
      "Epoch 82/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 83/500\n",
      "153/153 [==============================] - 0s 54us/sample - loss: nan\n",
      "Epoch 84/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 85/500\n",
      "153/153 [==============================] - 0s 57us/sample - loss: nan\n",
      "Epoch 86/500\n",
      "153/153 [==============================] - 0s 74us/sample - loss: nan\n",
      "Epoch 87/500\n",
      "153/153 [==============================] - 0s 69us/sample - loss: nan\n",
      "Epoch 88/500\n",
      "153/153 [==============================] - 0s 67us/sample - loss: nan\n",
      "Epoch 89/500\n",
      "153/153 [==============================] - 0s 69us/sample - loss: nan\n",
      "Epoch 90/500\n",
      "153/153 [==============================] - 0s 51us/sample - loss: nan\n",
      "Epoch 91/500\n",
      "153/153 [==============================] - 0s 54us/sample - loss: nan\n",
      "Epoch 92/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 93/500\n",
      "153/153 [==============================] - 0s 51us/sample - loss: nan\n",
      "Epoch 94/500\n",
      "153/153 [==============================] - 0s 57us/sample - loss: nan\n",
      "Epoch 95/500\n",
      "153/153 [==============================] - 0s 54us/sample - loss: nan\n",
      "Epoch 96/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 97/500\n",
      "153/153 [==============================] - 0s 51us/sample - loss: nan\n",
      "Epoch 98/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 99/500\n",
      "153/153 [==============================] - 0s 57us/sample - loss: nan\n",
      "Epoch 100/500\n",
      "153/153 [==============================] - 0s 54us/sample - loss: nan\n",
      "Epoch 101/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 102/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 103/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 104/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 105/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 106/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 107/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 108/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 109/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 110/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 111/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 112/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 113/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 114/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 115/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 116/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 117/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 118/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 119/500\n",
      "153/153 [==============================] - 0s 51us/sample - loss: nan\n",
      "Epoch 120/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 121/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 122/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 123/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 124/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 125/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 126/500\n",
      "153/153 [==============================] - 0s 52us/sample - loss: nan\n",
      "Epoch 127/500\n",
      "153/153 [==============================] - 0s 51us/sample - loss: nan\n",
      "Epoch 128/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 129/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 130/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 131/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 132/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 133/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 134/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 135/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 136/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 137/500\n",
      "153/153 [==============================] - 0s 35us/sample - loss: nan\n",
      "Epoch 138/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 139/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 140/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 141/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 142/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 143/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 144/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 145/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 146/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 147/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 148/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 149/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 150/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 151/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 152/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 153/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 154/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 155/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 156/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 157/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 158/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 159/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 160/500\n",
      "153/153 [==============================] - 0s 35us/sample - loss: nan\n",
      "Epoch 161/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 162/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 163/500\n",
      "153/153 [==============================] - 0s 33us/sample - loss: nan\n",
      "Epoch 164/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 165/500\n",
      "153/153 [==============================] - 0s 32us/sample - loss: nan\n",
      "Epoch 166/500\n",
      "153/153 [==============================] - 0s 32us/sample - loss: nan\n",
      "Epoch 167/500\n",
      "153/153 [==============================] - 0s 33us/sample - loss: nan\n",
      "Epoch 168/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 169/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 170/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 171/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 172/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 173/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 174/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 175/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 176/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 177/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 178/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 179/500\n",
      "153/153 [==============================] - 0s 35us/sample - loss: nan\n",
      "Epoch 180/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 181/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 182/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 183/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 184/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 185/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 186/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 187/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 188/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 189/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 190/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 191/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 192/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 193/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 194/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 195/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 196/500\n",
      "153/153 [==============================] - 0s 55us/sample - loss: nan\n",
      "Epoch 197/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 198/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 199/500\n",
      "153/153 [==============================] - 0s 52us/sample - loss: nan\n",
      "Epoch 200/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 201/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 202/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 203/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 204/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 205/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 206/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 207/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 208/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 209/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 210/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 211/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 212/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 213/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 214/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 215/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 216/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 217/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 218/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 219/500\n",
      "153/153 [==============================] - 0s 34us/sample - loss: nan\n",
      "Epoch 220/500\n",
      "153/153 [==============================] - 0s 35us/sample - loss: nan\n",
      "Epoch 221/500\n",
      "153/153 [==============================] - 0s 34us/sample - loss: nan\n",
      "Epoch 222/500\n",
      "153/153 [==============================] - 0s 34us/sample - loss: nan\n",
      "Epoch 223/500\n",
      "153/153 [==============================] - 0s 34us/sample - loss: nan\n",
      "Epoch 224/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 225/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 226/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 227/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 228/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 229/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 230/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 231/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 232/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 233/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 234/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 235/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 236/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 237/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 238/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 239/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 240/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 241/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 242/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 243/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 244/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 245/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 246/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 247/500\n",
      "153/153 [==============================] - 0s 35us/sample - loss: nan\n",
      "Epoch 248/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 249/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 250/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 251/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 252/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 253/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 254/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 255/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 256/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 257/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 258/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 259/500\n",
      "153/153 [==============================] - 0s 59us/sample - loss: nan\n",
      "Epoch 260/500\n",
      "153/153 [==============================] - 0s 51us/sample - loss: nan\n",
      "Epoch 261/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 262/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 263/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 264/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 265/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 266/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 267/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 268/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 269/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 270/500\n",
      "153/153 [==============================] - 0s 51us/sample - loss: nan\n",
      "Epoch 271/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 272/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 273/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 274/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 275/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 276/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 277/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 278/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 279/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 280/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 281/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 282/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 283/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 284/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 285/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 286/500\n",
      "153/153 [==============================] - 0s 53us/sample - loss: nan\n",
      "Epoch 287/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 288/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 289/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 290/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 291/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 292/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 293/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 294/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 295/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 296/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 297/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 298/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 299/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 300/500\n",
      "153/153 [==============================] - 0s 54us/sample - loss: nan\n",
      "Epoch 301/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 302/500\n",
      "153/153 [==============================] - 0s 53us/sample - loss: nan\n",
      "Epoch 303/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 304/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 305/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 306/500\n",
      "153/153 [==============================] - 0s 56us/sample - loss: nan\n",
      "Epoch 307/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 308/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 309/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 310/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 311/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 312/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 313/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 314/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 315/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 316/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 317/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 318/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 319/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 320/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 321/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 322/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 323/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 324/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 325/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 326/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 327/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 328/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 329/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 330/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 331/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 332/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 333/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 334/500\n",
      "153/153 [==============================] - 0s 53us/sample - loss: nan\n",
      "Epoch 335/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 336/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 337/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 338/500\n",
      "153/153 [==============================] - 0s 59us/sample - loss: nan\n",
      "Epoch 339/500\n",
      "153/153 [==============================] - 0s 53us/sample - loss: nan\n",
      "Epoch 340/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 341/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 342/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 343/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 344/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 345/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 346/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 347/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 348/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 349/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 350/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 351/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 352/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 353/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 354/500\n",
      "153/153 [==============================] - 0s 51us/sample - loss: nan\n",
      "Epoch 355/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 356/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 357/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 358/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 359/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 360/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 361/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 362/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 363/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 364/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 365/500\n",
      "153/153 [==============================] - 0s 52us/sample - loss: nan\n",
      "Epoch 366/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 367/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 368/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 369/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 370/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 371/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 372/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 373/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 374/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 375/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 376/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 377/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 378/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 379/500\n",
      "153/153 [==============================] - 0s 55us/sample - loss: nan\n",
      "Epoch 380/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 381/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 382/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 383/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 384/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 385/500\n",
      "153/153 [==============================] - 0s 51us/sample - loss: nan\n",
      "Epoch 386/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 388/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 389/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 390/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 391/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 392/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 393/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 394/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 395/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 396/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 397/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 398/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 399/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 400/500\n",
      "153/153 [==============================] - 0s 53us/sample - loss: nan\n",
      "Epoch 401/500\n",
      "153/153 [==============================] - 0s 50us/sample - loss: nan\n",
      "Epoch 402/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 403/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 404/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 405/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 406/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 407/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 408/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 409/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 410/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 411/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 412/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 413/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 414/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 415/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 416/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 417/500\n",
      "153/153 [==============================] - 0s 35us/sample - loss: nan\n",
      "Epoch 418/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 419/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 420/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 421/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 422/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 423/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 424/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 425/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 426/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 427/500\n",
      "153/153 [==============================] - 0s 34us/sample - loss: nan\n",
      "Epoch 428/500\n",
      "153/153 [==============================] - 0s 34us/sample - loss: nan\n",
      "Epoch 429/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 430/500\n",
      "153/153 [==============================] - 0s 43us/sample - loss: nan\n",
      "Epoch 431/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 432/500\n",
      "153/153 [==============================] - 0s 35us/sample - loss: nan\n",
      "Epoch 433/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 434/500\n",
      "153/153 [==============================] - 0s 34us/sample - loss: nan\n",
      "Epoch 435/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 436/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 437/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 438/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 439/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 440/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 441/500\n",
      "153/153 [==============================] - 0s 48us/sample - loss: nan\n",
      "Epoch 442/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 443/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 444/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 445/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 446/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 447/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 448/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 449/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 450/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 451/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 452/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 453/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 454/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 455/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 456/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 457/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 458/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 459/500\n",
      "153/153 [==============================] - 0s 59us/sample - loss: nan\n",
      "Epoch 460/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 461/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 462/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 463/500\n",
      "153/153 [==============================] - 0s 47us/sample - loss: nan\n",
      "Epoch 464/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 465/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 466/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 467/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 468/500\n",
      "153/153 [==============================] - 0s 38us/sample - loss: nan\n",
      "Epoch 469/500\n",
      "153/153 [==============================] - 0s 32us/sample - loss: nan\n",
      "Epoch 470/500\n",
      "153/153 [==============================] - 0s 35us/sample - loss: nan\n",
      "Epoch 471/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 472/500\n",
      "153/153 [==============================] - 0s 39us/sample - loss: nan\n",
      "Epoch 473/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 474/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 475/500\n",
      "153/153 [==============================] - 0s 34us/sample - loss: nan\n",
      "Epoch 476/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 477/500\n",
      "153/153 [==============================] - 0s 35us/sample - loss: nan\n",
      "Epoch 478/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 479/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 480/500\n",
      "153/153 [==============================] - 0s 40us/sample - loss: nan\n",
      "Epoch 481/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 482/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 483/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 484/500\n",
      "153/153 [==============================] - 0s 36us/sample - loss: nan\n",
      "Epoch 485/500\n",
      "153/153 [==============================] - 0s 34us/sample - loss: nan\n",
      "Epoch 486/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 487/500\n",
      "153/153 [==============================] - 0s 37us/sample - loss: nan\n",
      "Epoch 488/500\n",
      "153/153 [==============================] - 0s 35us/sample - loss: nan\n",
      "Epoch 489/500\n",
      "153/153 [==============================] - 0s 42us/sample - loss: nan\n",
      "Epoch 490/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 491/500\n",
      "153/153 [==============================] - 0s 46us/sample - loss: nan\n",
      "Epoch 492/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 493/500\n",
      "153/153 [==============================] - 0s 45us/sample - loss: nan\n",
      "Epoch 494/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 495/500\n",
      "153/153 [==============================] - 0s 52us/sample - loss: nan\n",
      "Epoch 496/500\n",
      "153/153 [==============================] - 0s 49us/sample - loss: nan\n",
      "Epoch 497/500\n",
      "153/153 [==============================] - 0s 44us/sample - loss: nan\n",
      "Epoch 498/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 499/500\n",
      "153/153 [==============================] - 0s 41us/sample - loss: nan\n",
      "Epoch 500/500\n",
      "153/153 [==============================] - 0s 55us/sample - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff9690b0b90>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow 2를 이용해서 Ozone 예제를 다시 구현해 보아요!\n",
    "# Multiple Linear Regression\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') # warning 출력을 하지 않아요\n",
    "\n",
    "\n",
    "# Raw data loading\n",
    "df = pd.read_csv('./data/ozone.csv')\n",
    "display(df)\n",
    "\n",
    "# 결측치 확인 및 처리\n",
    "# 일단 데이터가 충분히 많고 결측치가 적으면 삭제가 답이에요\n",
    "# 하지만 일반적으로 결측치를 삭제하면 데이터가 너무 많이 유실되기 때문에 다른 방식을 이용하게 되요!\n",
    "\n",
    "# print(df.isnull().sum())\n",
    "\n",
    "# Day, Month 제거\n",
    "df = df.drop(['Month','Day'],axis=1)\n",
    "\n",
    "# 결측치를 median으로 변경 \n",
    "df['Solar.R'][df['Solar.R'].isnull()] = df['Solar.R'].median()\n",
    "display(df)\n",
    "\n",
    "# 결측치 median 처리\n",
    "# x_data = df.loc[:,'Solar.R':]\n",
    "# x_data = df.iloc[:,1:]\n",
    "# for col in x_data.columns:\n",
    "#     col_median = np.nanmedian(x_data[col])\n",
    "#     x_data[col].loc[x_data[col].isnull()] = col_median\n",
    "\n",
    "\n",
    "# 2. 독립변수에 대한 이상치를 검출한 후 이 이상치는 mean 처리할게요\n",
    "\n",
    "# zscore = 1.8\n",
    "# for col in x_data.columns:\n",
    "#     outliers = x_data[col][np.abs(stats.zscore(x_data[col])) > zscore]\n",
    "#     col_mean = np.mean(x_data.loc[~x_data[col].isin(outliers),col])\n",
    "#     x_data.loc[x_data[col].isin(outliers),col] = col_mean\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 온전한데이터로 KNN 사용 Train 데이터 분류\n",
    "nan_df = df[df['Ozone'].isnull()]\n",
    "train_df = df[~df['Ozone'].isnull()]\n",
    "\n",
    "# display(train_df)\n",
    "x_data_train = train_df[['Solar.R', 'Wind','Temp']]\n",
    "t_data_train = train_df['Ozone']\n",
    "\n",
    "t_data_train= t_data_train.values.reshape(-1,1)\n",
    "\n",
    "# Normalization\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(x_data_train)\n",
    "x_data_train_norm = scaler_x.transform(x_data_train)\n",
    "\n",
    "scaler_t = MinMaxScaler()\n",
    "scaler_t.fit(t_data_train)\n",
    "t_data_train_norm = scaler_t.transform(t_data_train)\n",
    "\n",
    "\n",
    "# # Logistic Regression\n",
    "\n",
    "# sklearn_model = linear_model.LinearRegression()\n",
    "# sklearn_model.fit(x_data_train_norm, t_data_train_norm) # 학습\n",
    "# sklearn_model.predict\n",
    "\n",
    "# # KNN을 이용한 분류\n",
    "knn_model = KNeighborsRegressor(n_neighbors=3) # 이웃 3개 찾으라는 얘기\n",
    "knn_model.fit(x_data_train_norm, t_data_train_norm)\n",
    "nan_df['Ozone'] = scaler_t.inverse_transform(knn_model.predict(nan_df[['Solar.R', 'Wind','Temp']]))\n",
    "\n",
    "# KNN으로 예측된 데이터를 다시삽입\n",
    "# nan_df['Ozone'] = model.predict(nan_df[['Solar.R', 'Wind','Temp']])\n",
    "df = pd.concat([nan_df, train_df], axis = 0, sort =True)\n",
    "display(df)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# 예측값 확인\n",
    "test_data = [[310, 15, 80]]  # 테이스 데이터 !! Ozone량을 예측해 보아요\n",
    "x_data = df[['Solar.R', 'Wind','Temp']]\n",
    "t_data = df['Ozone']\n",
    "sklearn_model = linear_model.LinearRegression()\n",
    "sklearn_model.fit(x_data, t_data) # 학습\n",
    "print(sklearn_model.predict(test_data))\n",
    "\n",
    "\n",
    "\n",
    "# tensorflow 2.x\n",
    "# 모델생성\n",
    "keras_model = Sequential()\n",
    "# 레이어 추가\n",
    "keras_model.add(Flatten(input_shape=(3,))) # input layer\n",
    "# 코드상에 W와 b가 포함되어 있음 10월 12일 그림참조!\n",
    "keras_model.add(Dense(1, activation = 'linear'))  # output의 개수 // output layer\n",
    "\n",
    "# compile\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-2), loss='mse')\n",
    "\n",
    "# 학습\n",
    "keras_model.fit(x_data, t_data, epochs = 500, verbose = 1) # 정규화이후 확인\n",
    "\n",
    "# prediction\n",
    "print(keras_model.predict(test_data).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex  Age  Embarked  Family\n",
       "0           0       3    0  2.0         0       1\n",
       "1           1       1    1  2.0         1       1\n",
       "2           1       3    1  2.0         0       0\n",
       "3           1       1    1  2.0         0       1\n",
       "4           0       3    0  2.0         0       0\n",
       "..        ...     ...  ...  ...       ...     ...\n",
       "886         0       2    0  2.0         0       0\n",
       "887         1       1    1  1.0         0       0\n",
       "888         0       3    1  2.0         0       3\n",
       "889         1       1    0  2.0         1       0\n",
       "890         0       3    0  2.0         2       0\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived    0\n",
      "Pclass      0\n",
      "Sex         0\n",
      "Age         0\n",
      "Embarked    0\n",
      "Family      0\n",
      "dtype: int64\n",
      "sklearn의 정확도는 : 0.7910447761194029\n",
      "268/1 [========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 35us/sample - loss: 0.5677 - accuracy: 0.7612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5449802270576135, 0.76119405]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression에 대해서 sklearn과 Tensorflow 2.x구현을 해볼꺼에요\n",
    "# titanic(kaggle) => logistic문제 (결측치가 다수 있어요!)\n",
    "# feature engineering\n",
    "\n",
    "# 데이터를 완전히 준비합시다 \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./data/Titanic/train.csv')\n",
    "# display(df)\n",
    "\n",
    "df['Family'] = df['SibSp']|df['Parch']\n",
    "\n",
    "df['Sex'] = np.array(df['Sex'] == 'female', dtype = np.int32) \n",
    "df['Embarked'] = df['Embarked'].fillna('Q') # fillna 원하는 값으로 채움\n",
    "embarked_mapping = {'S' : 0 , 'C': 1, 'Q': 2}\n",
    "df['Embarked'] = df['Embarked'].map(embarked_mapping)\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "\n",
    "df.loc[df['Age'] < 8, 'Age'] = 0\n",
    "df.loc[(df['Age'] >= 8) & (df['Age'] < 20), 'Age'] = 1\n",
    "df.loc[(df['Age'] >= 20) & (df['Age'] < 65), 'Age'] = 2\n",
    "df.loc[df['Age'] >= 65, 'Age'] = 4\n",
    "df = df.drop(['PassengerId','Name','Ticket','Cabin','SibSp','Fare','Parch'], axis=1)\n",
    "\n",
    "display(df)\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "x_data_train, x_data_test, t_data_train, t_data_test =\\\n",
    "train_test_split(df.iloc[:,1:],df['Survived'],test_size=0.3, random_state=0)\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(x_data_train)\n",
    "x_data_train_norm = scaler_x.transform(x_data_train)\n",
    "x_data_test_norm = scaler_x.transform(x_data_test)\n",
    "\n",
    "sklearn_model = LogisticRegression()\n",
    "sklearn_model.fit(x_data_train_norm,t_data_train)\n",
    "sklearn_result = sklearn_model.score(x_data_test_norm,t_data_test)\n",
    "print('sklearn의 정확도는 : {}'.format(sklearn_result))\n",
    "\n",
    "\n",
    "# tensorflow 2.x로 구현\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Flatten(input_shape=(x_data_test_norm.shape[1],))) # column의 수\n",
    "keras_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-3), loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "t_data_train = np.array(t_data_train)\n",
    "t_data_test = np.array(t_data_test)\n",
    "\n",
    "result = keras_model.fit(x_data_train_norm, t_data_train, \n",
    "                         epochs = 1000, verbose = 0, validation_split=0.3)\n",
    "\n",
    "keras_result = keras_model.evaluate(x_data_test_norm,t_data_test)\n",
    "\n",
    "print(keras_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.keras.callbacks.History'>\n",
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(type(result))\n",
    "print(result.history.keys())\n",
    "plt.plot(result.history['accuracy'], color='b')\n",
    "plt.plot(result.history['val_accuracy'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn result : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1242\n",
      "           1       0.95      0.97      0.96      1429\n",
      "           2       0.92      0.90      0.91      1276\n",
      "           3       0.91      0.90      0.90      1298\n",
      "           4       0.92      0.92      0.92      1236\n",
      "           5       0.88      0.88      0.88      1119\n",
      "           6       0.93      0.95      0.94      1243\n",
      "           7       0.94      0.93      0.94      1334\n",
      "           8       0.89      0.88      0.88      1204\n",
      "           9       0.89      0.89      0.89      1219\n",
      "\n",
      "    accuracy                           0.92     12600\n",
      "   macro avg       0.92      0.92      0.92     12600\n",
      "weighted avg       0.92      0.92      0.92     12600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/opt/anaconda3/envs/data_env_tensorflow2/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Classification에 대해서 sklearn과 TF 2.x의 구현을 해보아요!\n",
    "# MNIST예제를 이용해서 구현해 보아요!\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('/Users/admin/Downloads/Digit_Recognizer_train.csv')\n",
    "display(df)\n",
    "\n",
    "# 결측치나 이상치는 없어요!!\n",
    "# Feature Engineering 할 필요가 없어요!\n",
    "\n",
    "# 독립변수와 종속변수 분리\n",
    "x_data = df.iloc[:,1:]\n",
    "t_data = df.iloc[:,0] # one-hot encoding 처리를 해야하는데 일단은 pass\n",
    "\n",
    "# normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)\n",
    "x_data_norm = scaler.transform(x_data)\n",
    "\n",
    "# Data Split\n",
    "x_data_train,x_data_test,t_data_train,t_data_test=\\\n",
    "train_test_split(x_data_norm, t_data, test_size=0.3, random_state=0)\n",
    "\n",
    "# 데이터 준비가 끝났어요 !! 이제 학습을 진행해 보아요!\n",
    "sklearn_model = LogisticRegression(solver='saga')\n",
    "# solver라는 개념이 있는데 default로 사용되는건 lbfgs라는 놈이에요!\n",
    "# lbfgs : 작은 데이터셋이 좋아요!, 데이터량이 많으면 성능이 별로에요!\n",
    "# 데이터량이 많은 경우 sag(Stochastic Average Gradient Descent)를 사용하면 더 좋아요!\n",
    "# 일반적으로 또 이걸 개량한 saga 를 더많이 이용해요!\n",
    "\n",
    "sklearn_model.fit(x_data_train, t_data_train) # 학습진행\n",
    "print('sklearn result : ')\n",
    "print(classification_report(t_data_test, \n",
    "                            sklearn_model.predict(x_data_test)))\n",
    "\n",
    "\n",
    "# TF 2.0 구현 \n",
    "# keras_model = Sequential()\n",
    "# keras_model.add(Flatten(input_shape=(x_data_train.shape[1],)))\n",
    "# keras_model.add(Dense(10, activation ='softmax'))\n",
    "# keras_model.compile(optimizer=SGD(learning_rate=1e-2),\n",
    "#                     loss = 'sparse_categorical_crossentropy',\n",
    "#                     metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "# t_data_train = np.array(t_data_train)\n",
    "# t_data_test = np.array(t_data_test)\n",
    "# history = keras_model.fit(x_data_train, t_data_train, epochs=500,\n",
    "#                           batch_size= 100, verbose = 0, validation_split=0.3)\n",
    "# print(keras_model.evaluate(x_data_test, t_data_test))\n",
    "# print('tensorflow result :')\n",
    "# print(classification_report(t_data_test, keras_model.predict(x_data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-be41bb64fb8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_data_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m print(classification_report(t_data_test, \n\u001b[1;32m      3\u001b[0m                             (tf.argmax(keras_model.predict(x_data_test), axis=1)).numpy()))\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras_model' is not defined"
     ]
    }
   ],
   "source": [
    "# print(classification_report(t_data_test, keras_model.predict(x_data_test)))\n",
    "print(classification_report(t_data_test, \n",
    "                            (tf.argmax(keras_model.predict(x_data_test), axis=1)).numpy()))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "history.history.keys()\n",
    "plt.plot(history.history['sparse_categorical_accuracy'], color='b')\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'], color='r')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env_tensorflow2] *",
   "language": "python",
   "name": "conda-env-data_env_tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
